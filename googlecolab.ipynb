{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-WKVp4Uukcl"
      },
      "source": [
        "#Install Server Requirements\n",
        "This should be run on a minimum of a T4 runtime, though it will run on a CPU only session, however long TTS generations may time out/error.\n",
        "\n",
        "This is a **work in progress**. Known issues:\n",
        "\n",
        "- The 1st TTS generation has a brief stutter.\n",
        "- RVC is not yet working.\n",
        "- Transcoding/ffmpeg isnt working.\n",
        "- Things yet to do on selecting your first model and other configuration setups.\n",
        "\n",
        "If you enable DeepSpeed for XTTS models, DeepSpeed has to compile on the 1st TTS generation which can take about 90 seconds. After that it should be fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ls-RHTQeZv",
        "outputId": "a20360b3-a5cb-48c5-b885-db89e8c143f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************\n",
            "** Server requirements installed ***\n",
            "*** Please proceed to next step ****\n",
            "************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown Mounting your Google Drive allows you to drag and drop samples/models via the `drive/Mydrive` path. This allows you<br>\n",
        "#@markdown to store or use specific audio samples or finetuned models.<br><br>\n",
        "#@markdown **Audio samples** need to be placed in `alltalk_tts/voices`<br>\n",
        "#@markdown **XTTS models** need to be placed in `alltalk_tts/models/xtts/{yourmodelfolderhere}`<br>\n",
        "mount_gdrive = False #@param{type:\"boolean\"}\n",
        "\n",
        "if mount_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "from IPython.display import clear_output\n",
        "print(\"*******************************************************************\")\n",
        "print(\"** Installing server requirements. This will take 5-10 minutes ****\")\n",
        "print(\"*******************************************************************\")\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 libaio-dev espeak-ng > '/dev/null' 2>&1\n",
        "clear_output()\n",
        "print(\"************************\")\n",
        "print(\"*** Cloning AllTalk ****\")\n",
        "print(\"************************\\n\")\n",
        "!git clone -b alltalkbeta https://github.com/erew123/alltalk_tts\n",
        "clear_output()\n",
        "print(\"\\n********************************\")\n",
        "print(\"*** Installing Requirements ****\")\n",
        "print(\"********************************\\n\")\n",
        "!python -m pip install --upgrade \"pip<24.1\"\n",
        "!pip install --quiet -r /content/alltalk_tts/system/requirements/requirements_colab.txt\n",
        "clear_output()\n",
        "print(\"\\n*****************************\")\n",
        "print(\"*** Installing DeepSpeed ****\")\n",
        "print(\"*****************************\\n\")\n",
        "!pip install deepspeed\n",
        "!pip install orjson\n",
        "!pip install faiss-cpu\n",
        "!pip install fairseq\n",
        "clear_output()\n",
        "print(\"\\n******************************\")\n",
        "print(\"*** Installing Cloudflare ****\")\n",
        "print(\"******************************\\n\")\n",
        "# Install cloudflare\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb > '/dev/null' 2>&1\n",
        "!apt install ./cloudflared-linux-amd64.deb aria2 > '/dev/null' 2>&1\n",
        "!rm cloudflared-linux-amd64.deb > '/dev/null' 2>&1\n",
        "!python -m spacy download en_core_web_md\n",
        "clear_output()\n",
        "print(\"\\n***************************\")\n",
        "print(\"*** Installing Cutlass ****\")\n",
        "print(\"***************************\\n\")\n",
        "# Clone the CUTLASS repository\n",
        "!git clone https://github.com/NVIDIA/cutlass.git\n",
        "!export CUTLASSPATH=/content/cutlass\n",
        "!sudo curl -L https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz -o /usr/local/bin/ffmpeg.tar.xz\n",
        "clear_output()\n",
        "%cd /usr/local/bin/\n",
        "clear_output()\n",
        "!7z e /usr/local/bin/ffmpeg.tar.xz -y\n",
        "clear_output()\n",
        "!7z e /usr/local/bin/ffmpeg.tar -y\n",
        "clear_output()\n",
        "!sudo chmod a+rx /usr/local/bin/ffmpeg\n",
        "clear_output()\n",
        "!pip uninstall jax -y\n",
        "clear_output()\n",
        "print(\"************************************\")\n",
        "print(\"** Server requirements installed ***\")\n",
        "print(\"*** Please proceed to next step ****\")\n",
        "print(\"************************************\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nk26r66RQ23"
      },
      "source": [
        "\n",
        "# Start AllTalk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "9PCQhSoiWvhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c6e4b0-7075-4d7c-f703-3b90e373414f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AllTalk TTS]\u001b[94m     _    _ _ \u001b[1;35m_____     _ _     \u001b[0m  _____ _____ ____  \n",
            "[AllTalk TTS]\u001b[94m    / \\  | | |\u001b[1;35m_   _|_ _| | | __ \u001b[0m |_   _|_   _/ ___| \n",
            "[AllTalk TTS]\u001b[94m   / _ \\ | | |\u001b[1;35m | |/ _` | | |/ / \u001b[0m   | |   | | \\___ \\ \n",
            "[AllTalk TTS]\u001b[94m  / ___ \\| | |\u001b[1;35m | | (_| | |   <  \u001b[0m   | |   | |  ___) |\n",
            "[AllTalk TTS]\u001b[94m /_/   \\_\\_|_|\u001b[1;35m |_|\\__,_|_|_|\\_\\ \u001b[0m   |_|   |_| |____/ \n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[92mConfig file update: \u001b[93mNo Updates required\u001b[0m\n",
            "[AllTalk TTS] \u001b[92mStart-up Mode     : \u001b[93mStandalone mode\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[92mThis is the first time startup. Please download a start TTS model.\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS]    \u001b[94mAvailable First Time Start-up models:\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS]    \u001b[93m1. \u001b[94mpiper - piper\u001b[0m\n",
            "[AllTalk TTS]    \u001b[93m2. \u001b[94mvits - tts_models--en--vctk--vits\u001b[0m\n",
            "[AllTalk TTS]    \u001b[93m3. \u001b[94mxtts - xttsv2_2.0.3\u001b[0m\n",
            "[AllTalk TTS]    \u001b[93m4.\u001b[94m I have my own models already\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS]    \u001b[94mIn \u001b[91m60 seconds\u001b[0m \u001b[94ma Piper model will be \u001b[91mdownloaded automatically.\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS]    \u001b[92mEnter your choice 1-4: \u001b[0m \n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] No input received. Proceeding with the default model (piper).\n",
            "/content/alltalk_tts/models/piper/en_US-ljspeech-high.onnx: 100% 114M/114M [00:01<00:00, 80.8MiB/s]\n",
            "/content/alltalk_tts/models/piper/en_US-ljspeech-high.onnx.json: 100% 4.97k/4.97k [00:00<00:00, 14.9MiB/s]\n",
            "[AllTalk TTS] piper model downloaded and configuration updated successfully.\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[93mIf you have you have UPGRADED from v1 ensure you have re-installed\u001b[0m\n",
            "[AllTalk TTS] \u001b[93mthe requirements. Otherwise you will get failures and errors!\u001b[0m\n",
            "[AllTalk TTS] \u001b[93mOn Linux ignore the \u001b[0m'sparse_attn requires a torch version' \u001b[93mand\u001b[0m\n",
            "[AllTalk TTS] \u001b[0m'using untested triton version' \u001b[93mmessages.\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[92mWAV file deletion :\u001b[93m Disabled\u001b[0m\n",
            "[AllTalk TTS] \u001b[92mGithub updated    :\u001b[93m 1st July 2024 at 08:57\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[94mGoogle Colab Detected\u001b[00m\n",
            "[AllTalk TTS]\n",
            "[AllTalk ENG] \u001b[92mTranscoding       :\u001b[93m ffmpeg found\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
            "[AllTalk ENG] \u001b[92mDeepSpeed version :\u001b[93m 0.14.4 \u001b[0m\n",
            "[AllTalk ENG] \u001b[92mPython Version    :\u001b[93m 3.10.12\u001b[0m\n",
            "[AllTalk ENG] \u001b[92mPyTorch Version   :\u001b[93m 2.3.1+cu121\u001b[0m\n",
            "[AllTalk ENG] \u001b[92mCUDA Version      :\u001b[93m 12.1\u001b[0m\n",
            "[AllTalk ENG]\n",
            "[AllTalk ENG]\u001b[94m Model/Engine :\u001b[93m Piper\u001b[94m Ready\u001b[0m\n",
            "[AllTalk ENG] \u001b[94mLoad time :\u001b[93m 0.00 seconds.\u001b[0m\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] \u001b[94mAPI Address :\u001b[00m \u001b[92mhttps://refresh-jackson-firefox-elementary.trycloudflare.com\u001b[00m\n",
            "[AllTalk TTS] \u001b[94mGradio Light:\u001b[00m \u001b[92mhttps://lawsuit-effectively-assessing-z.trycloudflare.com\u001b[00m\n",
            "[AllTalk TTS] \u001b[94mGradio Dark :\u001b[00m \u001b[92mhttps://lawsuit-effectively-assessing-z.trycloudflare.com?__theme=dark\u001b[00m\n",
            "[AllTalk TTS]\n",
            "themes/theme_schema@0.0.1.json: 100% 13.1k/13.1k [00:00<00:00, 45.7MB/s]\n",
            "[AllTalk TTS] Please use \u001b[91mCtrl+C\u001b[0m when exiting AllTalk otherwise a\n",
            "[AllTalk TTS] subprocess may continue running in the background.\n",
            "[AllTalk TTS]\n",
            "[AllTalk TTS] AllTalk Server Ready\n",
            "Downloading LICENSE.txt...\n",
            "100% 4.01k/4.01k [00:00<00:00, 11.6MiB/s]\n",
            "Downloading README.md...\n",
            "100% 4.26k/4.26k [00:00<00:00, 13.0MiB/s]\n",
            "Downloading config.json...\n",
            "100% 4.37k/4.37k [00:00<00:00, 12.1MiB/s]\n",
            "Downloading model.pth...\n",
            "100% 1.87G/1.87G [00:30<00:00, 61.2MiB/s]\n",
            "Downloading dvae.pth...\n",
            "100% 211M/211M [00:04<00:00, 50.7MiB/s]\n",
            "Downloading mel_stats.pth...\n",
            "100% 1.07k/1.07k [00:00<00:00, 2.90MiB/s]\n",
            "Downloading speakers_xtts.pth...\n",
            "100% 7.75M/7.75M [00:00<00:00, 77.9MiB/s]\n",
            "Downloading vocab.json...\n",
            "100% 361k/361k [00:00<00:00, 26.4MiB/s]\n",
            "[AllTalk Shutdown] \u001b[94mReceived Ctrl+C, terminating subprocess. Kill your Python processes if this fails to exit.\u001b[92m\n",
            "[AllTalk Shutdown] \u001b[94mReceived Ctrl+C, terminating subprocess. Kill your Python processes if this fails to exit.\u001b[92m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#@markdown Links to the API and Gradio interface will be shown when AllTalk has loaded in.<br>\n",
        "#@markdown The API address is what you would use in SillyTavern.<br>\n",
        "#@markdown Do not start this if you want to run Finetuning.\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def keep_alive():\n",
        "    while True:\n",
        "        time.sleep(60)  # Run every 60 seconds (adjust as needed)\n",
        "\n",
        "keep_alive_thread = threading.Thread(target=keep_alive)\n",
        "keep_alive_thread.start()\n",
        "\n",
        "Tunnel = \"cloudflare\"\n",
        "host = \"127.0.0.1\"\n",
        "ports = [7851, 7852]\n",
        "tunnel_urls = []\n",
        "\n",
        "# Starting tunnels for each port.\n",
        "for port in ports:\n",
        "    if Tunnel == \"cloudflare\":\n",
        "        !nohup cloudflared tunnel --url http://{host}:{port} > lt_{port}.log 2>&1 &\n",
        "    else:\n",
        "        !nohup npx lt -p {port} > lt_{port}.log 2>&1 &\n",
        "\n",
        "# Wait a couple of seconds for the tunnels to initialize.\n",
        "time.sleep(10)\n",
        "\n",
        "# Extract URLs for each tunnel.\n",
        "for port in ports:\n",
        "    log_file = f'lt_{port}.log'\n",
        "    with open(log_file, 'r') as testwritefile:\n",
        "        log_content = testwritefile.read()\n",
        "\n",
        "        # Use regular expressions to find the URL.\n",
        "        if Tunnel == \"cloudflare\":\n",
        "            url_match = re.search(r'(https://[-a-z0-9]+\\.trycloudflare\\.com)', log_content)\n",
        "        else:\n",
        "            url_match = re.search(r'your url is: (https?://\\S+)', log_content)\n",
        "\n",
        "        if url_match:\n",
        "            tunnel_url = url_match.group(1)\n",
        "            tunnel_urls.append(tunnel_url)\n",
        "        else:\n",
        "            print(f\"URL for port {port} not found.\")\n",
        "\n",
        "# Save the tunnel URLs to a JSON file.\n",
        "try:\n",
        "    # Try to open the JSON file for reading.\n",
        "    with open('/content/alltalk_tts/googlecolab.json', 'r') as f:\n",
        "        data = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    # If the file doesn't exist, create an empty dictionary.\n",
        "    data = {}\n",
        "\n",
        "data['google_ip_address'] = tunnel_urls\n",
        "\n",
        "# Write the modified data (or newly created data) back to the file.\n",
        "with open('/content/alltalk_tts/googlecolab.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "host = \"0.0.0.0\"\n",
        "\n",
        "if Tunnel == \"localtunnel\":\n",
        "    print(\"Before you copy the link above click on it and copy that ip:\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "\n",
        "# Start API server.\n",
        "!python /content/alltalk_tts/script.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Finetuning"
      ],
      "metadata": {
        "id": "gDzNPMwM7qvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Starts the Finetuning application for XTTS models.<br><br>\n",
        "#@markdown You can either run the `Start AllTalk` to download the base XTTS model(s) for finetuning. Or you can use the folder icon on the left hand<br>\n",
        "#@markdown side of the screen and upload an XTTS model that you want to finetune. If you are manually uploading a model, you would place your model<br>\n",
        "#@markdown files in `models/xtts/{yourmodelfolderhere}` and you will need all the models files in that folder `config.json, dvae.pth, mel_stats.pth,`<br>\n",
        "#@markdown `model.pth, speakers_xtts.pth, vocab.json`. Without 1x model available, Finetuning will not start.<br><br>\n",
        "#@markdown Likewise you can download your finetuned model from there, OR copy it to your Google Drive after finetuning, for later use in AllTalk.<br><br>\n",
        "#@markdown To access the Finetuning Gradio interface, connect to the `Google Colab Finetuning url` when Finetuning has started.<br>\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def keep_alive():\n",
        "    while True:\n",
        "        time.sleep(60)  # Run every 60 seconds (adjust as needed)\n",
        "\n",
        "keep_alive_thread = threading.Thread(target=keep_alive)\n",
        "keep_alive_thread.start()\n",
        "\n",
        "Tunnel = \"cloudflare\"\n",
        "host = \"127.0.0.1\"\n",
        "ports = [7052]\n",
        "tunnel_urls = []\n",
        "\n",
        "# Starting tunnels for each port.\n",
        "for port in ports:\n",
        "    if Tunnel == \"cloudflare\":\n",
        "        !nohup cloudflared tunnel --url http://{host}:{port} > lt_{port}.log 2>&1 &\n",
        "    else:\n",
        "        !nohup npx lt -p {port} > lt_{port}.log 2>&1 &\n",
        "\n",
        "# Wait a couple of seconds for the tunnels to initialize.\n",
        "time.sleep(10)\n",
        "\n",
        "# Extract URLs for each tunnel.\n",
        "for port in ports:\n",
        "    log_file = f'lt_{port}.log'\n",
        "    with open(log_file, 'r') as testwritefile:\n",
        "        log_content = testwritefile.read()\n",
        "\n",
        "        # Use regular expressions to find the URL.\n",
        "        if Tunnel == \"cloudflare\":\n",
        "            url_match = re.search(r'(https://[-a-z0-9]+\\.trycloudflare\\.com)', log_content)\n",
        "        else:\n",
        "            url_match = re.search(r'your url is: (https?://\\S+)', log_content)\n",
        "\n",
        "        if url_match:\n",
        "            tunnel_url = url_match.group(1)\n",
        "            tunnel_urls.append(tunnel_url)\n",
        "            print(f\"Google Colab Finetuning url: {tunnel_url}\\n\")\n",
        "            print(f\"********************************************************************\")\n",
        "            print(f\"**** Use the above URL to connect to Finetuning on Google Colab ****\")\n",
        "            print(f\"********************************************************************\")\n",
        "            print(f\"************* Now starting the Finetuning Application **************\")\n",
        "            print(f\"********************************************************************\\n\")\n",
        "        else:\n",
        "            print(f\"URL for port {port} not found.\")\n",
        "\n",
        "# Save the tunnel URLs to a JSON file.\n",
        "try:\n",
        "    # Try to open the JSON file for reading.\n",
        "    with open('/content/alltalk_tts/googlecolab.json', 'r') as f:\n",
        "        data = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    # If the file doesn't exist, create an empty dictionary.\n",
        "    data = {}\n",
        "\n",
        "data['google_ip_address'] = tunnel_urls\n",
        "\n",
        "# Write the modified data (or newly created data) back to the file.\n",
        "with open('/content/alltalk_tts/googlecolab.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "host = \"0.0.0.0\"\n",
        "\n",
        "if Tunnel == \"localtunnel\":\n",
        "    print(\"Before you copy the link above click on it and copy that ip:\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "\n",
        "# Start API server.\n",
        "!python /content/alltalk_tts/finetune.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Dewvq5s38Sfd",
        "outputId": "30689b4e-2af2-4595-f2be-8bf42753f355"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab Finetuning url: https://assistance-amazing-periods-payday.trycloudflare.com\n",
            "\n",
            "********************************************************************\n",
            "**** Use the above URL to connect to Finetuning on Google Colab ****\n",
            "********************************************************************\n",
            "\n",
            "[FINETUNE] HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
            "[FINETUNE] HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "Running on local URL:  http://127.0.0.1:7052\n",
            "[FINETUNE] HTTP Request: GET http://127.0.0.1:7052/startup-events \"HTTP/1.1 200 OK\"\n",
            "[FINETUNE] HTTP Request: HEAD http://127.0.0.1:7052/ \"HTTP/1.1 200 OK\"\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "[FINETUNE] Received interrupt signal. Cleaning up and exiting...\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}